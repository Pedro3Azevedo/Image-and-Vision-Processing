{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# <div align=\"center\">Instituto Superior de Engenharia de Lisboa</div>\n",
    "## <div align=\"center\">Licenciatura em Engenharia Informática e Multimédia</div>\n",
    "<br>\n",
    "<div align=\"center\">\n",
    "  <img src=\"images/isel.png\" alt=\"ISEL Logo\" width=\"300\">\n",
    "</div>\n",
    "\n",
    "## <div align=\"center\"><b>Processamento de Imagem e Visão</b></div>\n",
    "\n",
    "### <div align=\"center\"><h1>Trabalho Prático 2B - Deteção de Movimento</h1></div>\n",
    "\n",
    "<br>\n",
    "<div align=\"center\">\n",
    "  <b>Alunos:</b><br>\n",
    "  A45885 André Silva<br>\n",
    "  A47094 Pedro Azevedo <br><br>\n",
    "  \n",
    "  <b>Docente:</b>\n",
    "  Pedro Jorge\n",
    "</div>\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81b85faeb035c415"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Índice\n",
    "1. [Introdução](#introduction)\n",
    "2. [Estimação de imagem de fundo](#estimacao)\n",
    "3. [Deteção de pixeis ativos](#deteccao)\n",
    "4. [Utilização de operadores morfológicos](#operadores)\n",
    "5. [Deteção de regiões ativas](#deteccao)\n",
    "6. [Vizualiçação dos resultados do processamento](#visualizacao)\n",
    "7. [Conclusões](#conclusao)\n",
    "8. [Bibliografia](#bibliografia)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7cf28d158cb867c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "### 1. Introdução <a id=\"introducao\"></a>\n",
    "\n",
    "No âmbito da unidade curricular de Processamento de Imagem e Visão, foi proposto o desenvolvimento de um algoritmo de visão de computador que permita detetar, classificar, zonas da imagem onde ocorreram movimentos de objetos. Para tal, foi disponibilizado um video, que serve de base para o desenvolvimento do algoritmo. Adicionalmente, foi lecionado nas aulas teóricas e práticas, um conjunto de técnicas e algoritmos que permitem a resolução deste problema. Como a estimação de imagem de fundo, deteção de pixeis ativos, a utilização de operadores morfológicos e de regióes ativas e por fim a classificação das mesmas. Assim, para o desenvolvimento do trabalho, foi utilizado a linguagem de programação Python e a biblioteca OpenCV, que permite a utilização de algoritmos de visão de computador.\n",
    "\n",
    "Neste relatório realizado em Jupyter Notebook, é apresentado o desenvolvimento do algoritmo, bem como a sua explicação e justificação. Para tal, o relatório está dividido em 5 secções, que correspondem às 5 fases de desenvolvimento do algoritmo. Cada secção é composta por uma breve explicação do algoritmo desenvolvido, acompanhado pela sua implementação em Python. No final do relatório, é apresentado o video final, que contém o resultado do processamento do video base, bem como uma breve conclusão do trabalho realizado.\n",
    "\n",
    "\n",
    "\n",
    "Sequencia de tarefas:\n",
    "- Estimação de imagem de fundo (Sugestão: usar a filtragem temporal com filtrode mediana)\n",
    "- Deteção de pixeis ativos.\n",
    "- Utilização de operadores morfológicos\n",
    "- Deteção de regiões ativas\n",
    "- Classificação e correspondência de regiões ativas (Sugestão para a correspondência: \"People tracking in surveillance applications\", Luis M.Fuentes & Sergio A. Velastin, Proceedings 2nd IEEE Int. Workshop on PETS, Kauai, Hawaii, USA, 2001)\n",
    "- Vizualiçação dos resultados do processamento."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f81aabb7aeb11ae"
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-29T17:00:54.407193400Z",
     "start_time": "2023-12-29T17:00:54.384388500Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2 - Estimação de imagem de fundo <a id=\"estimacao\"></a>\n",
    "\n",
    "Primeiro passo para detetar movimento é estimar a imagem de fundo, para que, frame a frame se compare com o fundo estimado detetar movimento.\n",
    "Para estimar o fundo, é necessário fazer a mediana temporal, ou seja, calcular a mediana de cada pixel ao longo do tempo, dos frames selecionados. Como se retirasse os objetos em movimento, e ficasse apenas com o fundo. Como ao longo do tempo o fundo alterasse, ou existe mudança de luz, ou no caso do video de teste, existem carros estacionados que saem e outros que estacionam, é necessário, ao longo do processamento dos frames, ir recalculando o fundo estimado. Ao longo do processamento, escolheu-se estimar o fundo a cada 300 frames, ou seja, a cada 300 frames, é recalculado o fundo estimado, com os 300 frames anteriores, adicioando os frames a lista \"frames_estimar_fundo\", utilizando o metodo \"read()\", que lê o frame seguinte do video."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b15dae7573d12e22"
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "outputs": [],
   "source": [
    "def estimar_fundo(frames_estimar_fundo, frame):\n",
    " # Estimar o fundo\n",
    "    if frames_estimar_fundo:\n",
    "        return np.median(frames_estimar_fundo, axis=0).astype(np.uint8)\n",
    "    else:\n",
    "        # Lida com o caso em que a lista está vazia (nenhum frame disponível)\n",
    "       return np.zeros_like(frame)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T17:00:54.444122800Z",
     "start_time": "2023-12-29T17:00:54.412817300Z"
    }
   },
   "id": "2a28251e9f84558b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3 - Deteção de pixeis ativos <a id=\"deteccao\"></a>:\n",
    "\n",
    "Para detetar pixeis ativos, é necessário comparar o frame com o fundo estimado, e aplicar um limiar para detetar pixeis ativos, subtraindo pixel a pixel, e comparando com um limiar, se for maior, é pixel ativo, se for menor, é pixel inativo.\n",
    "Antes de fazer a diferença entre o frame e o fundo estimado, é necessário decidir se se vai utilizar as imagens a cor ou a escala de cinzento. Para este trabalho, optou-se por utilizar a cores, embora tenha uma complexidade computacional maior, e ocupe mais espaço em memória e armazenamento, tem a capacidade de discriminar melhor objetos semelhantes, e tem mais informação de cor, que pode ser necessária para a classificação das regiões ativas.\n",
    "\n",
    "Para calcular a diferença, utilizou-se a função \"cv.absdiff()\", onde se passa como argumentos o frame e o fundo estimado, e retorna a diferença absoluta entre os dois. Para comparar com o limiar, é necessário comverter a diferença em escla de cinzento, utilizando a função \"cv.cvtColor()\". Para aplicar o limiar, utilizou-se a função \"cv.threshold()\", onde se passa como argumentos a diferença, o limiar, o valor máximo, e o tipo de limiarização, neste caso, binário. O valor máximo é 255, pois é o valor máximo de um pixel em escala de cinza, e o tipo de limiarização é binário, pois queremos apenas dois valores, 0 ou 255, ou seja, preto ou branco. Caso o valor do pixel seja maior que o limiar, é atribuído o valor 255, caso seja menor ou igual, é atribuído o valor 0, tendo no final uma imagem bonaria onde os pixeis ativos são brancos, e os pixeis inativos são pretos."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59a06c0675d10f16"
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "outputs": [],
   "source": [
    "def pixels_ativos(frame, fundoEstimado, limiar=10):\n",
    "    \n",
    "    # Calcula a diferença absoluta entre o frame e o fundo estimado\n",
    "    diferenca = cv.absdiff(frame, fundoEstimado)\n",
    "    \n",
    "    # Converte a diferença para monocromático para aplocar um limiar\n",
    "    diferenca_gray = cv.cvtColor(diferenca, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Aplica um limiar para identificar os pixels ativos\n",
    "    _, pixels_ativos = cv.threshold(diferenca_gray, limiar, 255, cv.THRESH_BINARY)\n",
    "    \n",
    "    return pixels_ativos"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T17:00:54.460650500Z",
     "start_time": "2023-12-29T17:00:54.448524800Z"
    }
   },
   "id": "b82d0e57c3004d69"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4 - Utilização de operadores morfológicos <a id=\"operadores\"></a>: \n",
    "\n",
    "Ao identificar as regioes ativas, estas não vão ser perfeitas, e vão ter ruído, para isso, é necessário aplicar operadores morfológicos, para eliminar o ruído, e melhorar a qualidade das regiões ativas. Aplicou-se então os operadores de fechamento, erosão e dilatação, para eliminar ruido e melhorar a qualidade das regiões ativas. Para tal, utilizou-se as funções \"cv.getStructuringElement()\", \"cv.morphologyEx()\", \"cv.erode()\" e \"cv.dilate()\". Para o operador de fechamento, utilizou-se um kernel retangular de 5x5, para a erosão, utilizou-se um kernel elíptico de 5x5, e para a dilatação, utilizou-se um kernel cruz de 3x8. Alterando os parametros dos kernels, ou das interações, podemos obter resultados diferentes, sendo que esta definição de kernels e interações, foi uma que obteve bons resultados."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8be51858b4ea1204"
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "outputs": [],
   "source": [
    "def operadores_morfologicos(frame):\n",
    "\n",
    "    # Aplicar operação de fechamento\n",
    "    kernel_close = cv.getStructuringElement(cv.MORPH_RECT, (5, 5))\n",
    "    nframe = cv.morphologyEx(frame, cv.MORPH_CLOSE, kernel_close)\n",
    "\n",
    "\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, (5, 5))\n",
    "    nframe = cv.erode(nframe, kernel, iterations=2)\n",
    "\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_CROSS, (3, 8))\n",
    "    nframe = cv.dilate(nframe, kernel, iterations=5)\n",
    "\n",
    "    return nframe"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T17:00:54.463951100Z",
     "start_time": "2023-12-29T17:00:54.456707600Z"
    }
   },
   "id": "7238444029a8a761"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5 - Classificação das regiões ativas <a id=\"classificacao\"></a>:\n",
    "\n",
    "Tendo as regiões ativas, falta identifica-as, extrair as propriedades e classifica-las. \n",
    "Aplicando o \"findCountours()\", é possível identificar os contornos das regiões ativas, e com o \"boundingRect()\", consegue-se obter o retângulo que envolve o contorno. \n",
    "Através das propriedades do retângulo de cada contorno, é possível extrair as caracteristicas da região, como a área, o aspect ratio, a posição vertical, o histograma de cores e o centro, aplicando certas formulass matemáticas e do OpenCV:\n",
    "\n",
    "Area - cv.contourArea(contorno)\n",
    "Aspect Ratio - Largura / Altura\n",
    "Posição Vertical - Posição Y / Numero de linhas da imagem\n",
    "Histograma de Cores - media das cores do retângulo, selecionando apenas as 3 componentes de cores RGB, \"cv.mean(frame_original[y:y + h, x:x + w])[:3]\"\n",
    "Centro - Posição X + Largura / 2, Posição Y + Altura / 2\n",
    "\n",
    "Com estas propriedades, é possível classificar a região, comparando os valores das propriedades com certos limiares definidos, e aplicando a seguinte lógica:\n",
    "\n",
    "Se o aspect ratio for maior que o limiar de aspect ratio de carro, e a posição vertical for menor que o limiar de posição vertical, a região é um carro.\n",
    "Se o aspect ratio for menor que o limiar de aspect ratio de pessoa, e a posição vertical for maior que o limiar de posição vertical de pessoa, a região é uma pessoa.\n",
    "Se não for nenhuma das anteriores, a região é outra.\n",
    "\n",
    "Os limiares foram definidos experimentalmente, analisando o resultado e ajustando os valores consuante o resultado obtido, tendo estes os valores dos limiares:\n",
    "Limiar de aspect ratio de carro: 0.50\n",
    "Limiar de aspect ratio de pessoa: 0.60\n",
    "Limiar de posição vertical: 0.80\n",
    "Limiar de posição vertical de pessoa: 0.50\n",
    "\n",
    "Se houver alteração nos operadores morfológicos, estes parametros têm que ser ajustados, pois o tamanho das regiões vai ser diferente.\n",
    "\n",
    "Por fim, é necessário desenhar o retângulo e o resultado da classificação da região ativa, para isso, utilizou-se as funções \"cv.drawContours()\", sendo que para cada categoria, é atrbuida uma cor diferente, e \"cv.putText()\", onde se escreve a categoria, o aspect ratio e a posição vertical, no retângulo da região ativa.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "edb9b51b0a1f213a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def active_region(frame_f, frame_bin, min_width, min_height):\n",
    "    contours, _ = cv.findContours(frame_bin, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Lista para armazenar os contours que correspondem a regiões ativas neste frame\n",
    "    contours_atuais = []\n",
    "\n",
    "    for (i, c) in enumerate(contours):\n",
    "        (x, y, w, h) = cv.boundingRect(c)  # Obtém as coordenadas do retângulo\n",
    "\n",
    "        valid_contour = (w >= min_width) and (h >= min_height)  # Verifica se o retângulo é válido\n",
    "        if not valid_contour:\n",
    "            continue\n",
    "\n",
    "        # Extrai características da região\n",
    "        propriedades = extrair_caracteristicas_regiao(c, x, y, w, h, frame_f)\n",
    "        area, aspect_ratio, posicao_vertical, histograma_cores, centro = propriedades\n",
    "        # Classifica a região com base nas características\n",
    "        categoria = classificar_regiao(c, propriedades)\n",
    "\n",
    "        # Adiciona o contour atual à lista\n",
    "        contours_atuais.append(c)\n",
    "\n",
    "        # Desenha o retângulo colorido de acordo com a categoria\n",
    "        cor_retangulo = (0, 255, 0) if categoria == \"Pessoa\" else (255, 0, 0) if categoria == \"Carro\" else (0, 0, 255)\n",
    "        cv.rectangle(frame_f, (x, y), (x + w, y + h), cor_retangulo, 2)\n",
    "\n",
    "        # Escreve as propriedades e a label\n",
    "\n",
    "        cv.putText(frame_f, \"AR: {:.2f}\".format(aspect_ratio), (x, y - 5), cv.FONT_HERSHEY_SIMPLEX, 0.5, cor_retangulo, 2)\n",
    "        cv.putText(frame_f, \"PV: {:.2f}\".format(posicao_vertical), (x, y + h + 15), cv.FONT_HERSHEY_SIMPLEX, 0.5, cor_retangulo, 2)\n",
    "        cv.putText(frame_f, f\"{categoria}\", (x, y + h + 30), cv.FONT_HERSHEY_SIMPLEX, 0.5, cor_retangulo, 2)\n",
    "\n",
    "    return frame_f\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T17:00:54.473109Z",
     "start_time": "2023-12-29T17:00:54.466321700Z"
    }
   },
   "id": "e5e75b543f5532e4",
   "execution_count": 244
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "outputs": [],
   "source": [
    "def extrair_caracteristicas_regiao(contorno, x, y, w, h, frame_original):\n",
    "    area = cv.contourArea(contorno)\n",
    "    aspect_ratio = w / h if h != 0 else 0\n",
    "    posicao_vertical = y / frame_original.shape[0]\n",
    "    histograma_cores = cv.mean(frame_original[y:y + h, x:x + w])[:3]\n",
    "    centro = (x + w // 2, y + h // 2)\n",
    "\n",
    "\n",
    "    return area, aspect_ratio, posicao_vertical, histograma_cores, centro"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T17:00:54.500835800Z",
     "start_time": "2023-12-29T17:00:54.474633500Z"
    }
   },
   "id": "e0369224e1ddc772"
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "outputs": [],
   "source": [
    "def classificar_regiao(contorno, propriedades):\n",
    "    \n",
    "    area, aspect_ratio, posicao_vertical, histograma_cores, _ = propriedades\n",
    "    limiar_aspect_ratio_carro = 0.50  # Limiar para aspect ratio de carro (0.38 - 1.n) (pessoa < .50)\n",
    "    limiar_aspect_ratio_pessoa = 0.60  # Limiar para aspect ratio de pessoa \n",
    "    limiar_posicao_vertical = 0.80  # Limiar para posição vertical (carro 0.56) (pessoa: 0.80 > 506\n",
    "    limiar_posicao_vertical_pessoa = 0.50  # Limiar para posição vertical de pessoa (carro 0.56) (pessoa: 0.80 > 506\n",
    "\n",
    "    # Lógica de classificação\n",
    "    if aspect_ratio >= limiar_aspect_ratio_carro and posicao_vertical <= limiar_posicao_vertical:\n",
    "        categoria = \"Carro\"\n",
    "    elif aspect_ratio <= limiar_aspect_ratio_pessoa and posicao_vertical >= limiar_posicao_vertical_pessoa:\n",
    "        categoria = \"Pessoa\"\n",
    "    else:\n",
    "        categoria = \"Outro\"\n",
    "\n",
    "    \n",
    "    return categoria"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T17:00:54.500898900Z",
     "start_time": "2023-12-29T17:00:54.481791300Z"
    }
   },
   "id": "4529d4e9d066c685"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6 - Vizualiçação dos resultados do processamento <a id=\"visualizacao\"></a>:\n",
    "\n",
    "Nesta função, começa-se por ler o video, e definir o número de frames que vão ser utilizados para estimar o fundo, neste caso, 300. De seguida, é necessário definir o número total de frames do video, para que o processamento pare quando chegar ao fim do video. \n",
    "De seguida, é necessário definir as configurações para guardar o video final, como o fps, a largura e altura, e o codec.\n",
    "\n",
    "Para começar o processamento do video, verifica-se se o número de frames que faltam processar, estão dentro do numero de frames que vão ser utilizados para estimar o fundo, se não estiverem, o número de frames que vão ser utilizados para estimar o fundo, é igual ao número de frames que faltam processar. De seguida, é necessário iniciar as listas de frames que vão ser utilizados para estimar o fundo, e os frames que vão ser processados. Estima-se o fundo, e percorre-se a lista de frames a serem processados, aplicando as funções anteriores, e adicionando o resultado à lista de frames finais, incrementando também o número de frames processados. Por fim, escreve-se o video final, e quando o processamento termina, fecha-se o video e o video final."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b055ad1e01747b3"
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "outputs": [],
   "source": [
    "def processar_video(video_path):\n",
    "    vid = cv.VideoCapture(video_path)\n",
    "    nFramesFundo = 300\n",
    "    nFramesProcessados = 0\n",
    "    nTotalFrames = int(vid.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "    framesFinais = []\n",
    "\n",
    "\n",
    "    # Configuração para salvar o vídeo final\n",
    "    fps = int(vid.get(cv.CAP_PROP_FPS))\n",
    "    width = int(vid.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(vid.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "    fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
    "    output_video = cv.VideoWriter('output_video.avi', fourcc, fps, (width, height))\n",
    "\n",
    "    try:\n",
    "        # Enquanto houver vídeo\n",
    "        while nFramesProcessados < nTotalFrames:\n",
    "            if nTotalFrames - nFramesProcessados < nFramesFundo:\n",
    "                nFramesFundo = nTotalFrames - nFramesProcessados\n",
    "    \n",
    "            # Iniciar a lista de frames que vão estimar o fundo\n",
    "            frames_estimar_fundo = []\n",
    "            # Iniciar a lista de frames que vão ser processados\n",
    "            framesPorProcessar = []\n",
    "    \n",
    "            for i in range(nFramesFundo):\n",
    "                ret, frame = vid.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "    \n",
    "                # Adicionar à lista dos frames que vão estimar o fundo\n",
    "                frames_estimar_fundo.append(frame)\n",
    "                # Adicionar à lista dos frames que vão ser processados\n",
    "                framesPorProcessar.append(frame)\n",
    "            \n",
    "            fundo_estimado = estimar_fundo(frames_estimar_fundo, frame)\n",
    "    \n",
    "           \n",
    "    \n",
    "            # Processar os primeiros 500 frames\n",
    "            for frame in framesPorProcessar:\n",
    "                # Calcular os pixels ativos\n",
    "                frame_bin = pixels_ativos(frame, fundo_estimado, 50)\n",
    "                # Aplicar operadores morfológicos\n",
    "                frame_operadores = operadores_morfologicos(frame_bin)\n",
    "                # Processar as regiões ativas e obter o novo mapa de regiões ativas\n",
    "                frame_final= active_region(frame, frame_operadores, 5, 5)\n",
    "                framesFinais.append(frame_final)\n",
    "                nFramesProcessados += 1\n",
    "                # Escrever o vídeo final\n",
    "                output_video.write(frame_final)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro: {e}\")\n",
    "\n",
    "    finally:\n",
    "        vid.release()\n",
    "        output_video.release()\n",
    "        cv.destroyAllWindows()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T17:00:54.500898900Z",
     "start_time": "2023-12-29T17:00:54.491016200Z"
    }
   },
   "id": "be105c4c2ebc3804"
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "outputs": [],
   "source": [
    "processar_video(\"camera1.avi\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T17:03:38.160827100Z",
     "start_time": "2023-12-29T17:00:54.496292400Z"
    }
   },
   "id": "b48b475808c79135"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7 - Conclusão <a id=\"conclusao\"></a>:\n",
    "\n",
    "Após o procecssamento do video, conseguimos concluir que o algoritmo desenvolvido, consegue detetar e classificar as regiões ativas, tem certas falhas em relação a deteção das regiões, onde estas ficam mais pequenas, não conseguindo identificar como qualquer objeto, ou ficar classificar como outro objeto. Para chegar a a um melhor resultado, teria que se ajustar os parametros dos operadores morfologicos.\n",
    "Para melhorar o algoritmo, poderia-se fazer a correspondencia entre regiões, através da propriedade do centro de cada região e medir a distancia euclidiana entre os centros do frame anterior.\n",
    " "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18765a1e1a5a327b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 8 - Bibliografia <a id=\"bibliografia\"></a>:\n",
    "\n",
    "- https://docs.opencv.org/4.x/d2/d96/tutorial_py_table_of_contents_imgproc.html\n",
    "- Acetatos Capítulo 7 - Análise de Movimento, Professor Arnaldo Abrantes\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5f293d2b01dfabb9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
